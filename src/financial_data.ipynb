{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os\n",
    "import string\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from marketdata.tickers import companies\n",
    "from loguru import logger\n",
    "from sqlalchemy import create_engine\n",
    "import sqlite3 as sql\n",
    "import mysql.connector\n",
    "import pymongo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = \"/home/blackwolf/dev/projects/finance/market-ai/\"\n",
    "db = os.path.join(db_path, \"marketdata.db\")\n",
    "mysql_uri = \"mysql+mysqlconnector://root:root@localhost:3306/marketdata\"\n",
    "engine = create_engine(mysql_uri)\n",
    "path = os.getcwd()\n",
    "\n",
    "client = pymongo.MongoClient(os.environ.get(\"MONGO_ATLAS_FINANCE\"))\n",
    "db = client[\"stockdata\"]\n",
    "collection = db[\"fundamentals\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from marketdata.models.sqlite_db import _query_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 00:49:13.553 | SUCCESS  | marketdata.models.sqlite_db:_query_symbols:60 - [+] All symbols retrieved\n"
     ]
    }
   ],
   "source": [
    "stocks = _query_symbols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from marketdata.models.sqlite_db import select_fundamental_data, select_quote_data\n",
    "qd = select_quote_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = select_fundamental_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd.reset_index(inplace=True)\n",
    "fd_dict = fd.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "documents must be a non-empty list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m collection\u001b[39m.\u001b[39;49minsert_many({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: fd_dict})\n",
      "File \u001b[0;32m~/projects/finance/market-ai/.venv/lib/python3.8/site-packages/pymongo/_csot.py:105\u001b[0m, in \u001b[0;36mapply.<locals>.csot_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[39mwith\u001b[39;00m _TimeoutContext(timeout):\n\u001b[1;32m    104\u001b[0m             \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 105\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/projects/finance/market-ai/.venv/lib/python3.8/site-packages/pymongo/collection.py:691\u001b[0m, in \u001b[0;36mCollection.insert_many\u001b[0;34m(self, documents, ordered, bypass_document_validation, session, comment)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[39m\"\"\"Insert an iterable of documents.\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \n\u001b[1;32m    644\u001b[0m \u001b[39m  >>> db.test.count_documents({})\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[39m.. versionadded:: 3.0\u001b[39;00m\n\u001b[1;32m    685\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    686\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    687\u001b[0m     \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(documents, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m    688\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(documents, abc\u001b[39m.\u001b[39mMapping)\n\u001b[1;32m    689\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m documents\n\u001b[1;32m    690\u001b[0m ):\n\u001b[0;32m--> 691\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdocuments must be a non-empty list\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    692\u001b[0m inserted_ids: List[ObjectId] \u001b[39m=\u001b[39m []\n\u001b[1;32m    694\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgen\u001b[39m():\n",
      "\u001b[0;31mTypeError\u001b[0m: documents must be a non-empty list"
     ]
    }
   ],
   "source": [
    "collection.insert_many({\"data\": fd_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytz import timezone\n",
    "import requests, os, json\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "import time\n",
    "from datetime import datetime\n",
    "import asyncio\n",
    "\n",
    "PATH = \"../tmp/\"\n",
    "FILE = \"scraper.log\"\n",
    "LOG_FILE = os.path.join(PATH, FILE)\n",
    "logger.add(LOG_FILE, format=\"{time:MM/DD/YYYY at HH:mm:ss} | {level} | {name} | {message}\", diagnose=True, backtrace=True)\n",
    "\n",
    "\n",
    "today = datetime.today()\n",
    "today_fmt = today.strftime(\"%m-%d-%Y\")\n",
    "TDA_BASE = \"https://api.tdameritrade.com/v1/\"\n",
    "TDA_APIKEY = os.environ.get('TDA_APIKEY')\n",
    "\n",
    "\n",
    "# DATE BUILDING AND MANAGEMENT\n",
    "today = datetime.today().astimezone(timezone(\"US/Central\"))\n",
    "today_fmt = today.strftime(\"%m-%d-%Y\")\n",
    "\n",
    "# CREATE THE LOGGER FOR THIS SCRIPT:\n",
    "log_path = str(os.path.pardir) + '/logs/'\n",
    "base_fmt = \"[{time:YYYY-MM-DD at HH:mm:ss}]|[{name}-<lvl>{message}</lvl>]\"\n",
    "logger.add(log_path+\"quotes.log\", rotation=\"2 MB\",\n",
    "           colorize=True, enqueue=True, catch=True)\n",
    "\n",
    "class Fundamental:\n",
    "\n",
    "    def __init__(self, stocks: list):\n",
    "        self.stocks = stocks\n",
    "        self.stock_chunks = self.chunks(stocks)\n",
    "        # self.engine = create_marketdata_engine()\n",
    "\n",
    "    # This function chunks the list of symbols into groups of 200\n",
    "    def chunks(self, l: list, n: int = 200):\n",
    "        \"\"\"\n",
    "        :param l: takes in a list\n",
    "        :param n: Lets you know how long you want each chunk to be\n",
    "        \"\"\"\n",
    "        n = max(1, n)\n",
    "        logger.info(\"[+] Stocks chunked into groups of 200..\")\n",
    "        return (l[i: i + n] for i in range(0, len(l), n))\n",
    "\n",
    "    def data(self, stock):\n",
    "        \"\"\"\n",
    "        :param stocks: List of stocks chunked into 200 symbol chunks\n",
    "        :return: This will return tons of information that will then\n",
    "        be changed into dataframes and inserted into the database.\n",
    "        \"\"\"\n",
    "        url = TDA_BASE + \"instruments\"\n",
    "\n",
    "        # pass params\n",
    "        params = {\"apikey\": TDA_APIKEY, \"symbol\": stock,\n",
    "                  \"projection\": \"fundamental\"}\n",
    "\n",
    "        request = requests.get(url=url, params=params).json()\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "        # create df\n",
    "        _df = pd.DataFrame.from_dict(\n",
    "            request, orient=\"index\").reset_index(drop=\"True\")\n",
    "\n",
    "        def _reshape_fundamentals(df):\n",
    "\n",
    "            _fund_list = list(df[\"fundamental\"])\n",
    "            _df = pd.DataFrame([x for x in _fund_list])\n",
    "            return _df\n",
    "\n",
    "        df = _reshape_fundamentals(_df)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def execute_main(self):\n",
    "        \"\"\"\n",
    "        :Description: Main method to obtain Fundamental data for every stock in the stocks list\n",
    "        passed to the Fundamental() class when instantiated. This method will execute the\n",
    "        Fundamental.data method using a chunked stocks list.\n",
    "        \"\"\"\n",
    "        logger.info(\"[-] Executing the main Fundamental Object Method\")\n",
    "        try:\n",
    "            fundamental_data = pd.concat([self.data(each)\n",
    "                                   for each in self.stock_chunks])\n",
    "            logger.info(\"[+] Fundamental Data Received\")\n",
    "            # insert_fundamental_data_mysql(fundamental_data, self.engine)\n",
    "            return pd.DataFrame(fundamental_data)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(\"Error Caused Due to {}\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fundamental:\n",
    "\n",
    "    def __init__(self, stocks: list):\n",
    "        self.stocks = stocks\n",
    "        self.stock_chunks = self.chunks(stocks)\n",
    "        # self.engine = create_marketdata_engine()\n",
    "\n",
    "    # This function chunks the list of symbols into groups of 200\n",
    "    def chunks(self, l: list, n: int = 200):\n",
    "        \"\"\"\n",
    "        :param l: takes in a list\n",
    "        :param n: Lets you know how long you want each chunk to be\n",
    "        \"\"\"\n",
    "        n = max(1, n)\n",
    "        logger.info(\"[+] Stocks chunked into groups of 200..\")\n",
    "        return (l[i: i + n] for i in range(0, len(l), n))\n",
    "\n",
    "    def data(self, stock):\n",
    "        \"\"\"\n",
    "        :param stocks: List of stocks chunked into 200 symbol chunks\n",
    "        :return: This will return tons of information that will then\n",
    "        be changed into dataframes and inserted into the database.\n",
    "        \"\"\"\n",
    "        url = TDA_BASE + \"instruments\"\n",
    "\n",
    "        # pass params\n",
    "        params = {\"apikey\": TDA_APIKEY, \"symbol\": stock,\n",
    "                  \"projection\": \"fundamental\"}\n",
    "\n",
    "        request = requests.get(url=url, params=params).json()\n",
    "\n",
    "        time.sleep(1)\n",
    "        \n",
    "        return request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 01:03:15.013 | INFO     | __main__:chunks:15 - [+] Stocks chunked into groups of 200..\n"
     ]
    }
   ],
   "source": [
    "fund = Fundamental(stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fund.data(stock for stock)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a3e50fa61fc4f11c923305726539e4556f8723b183a81ab6015b69194538abd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
