{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os\n",
    "import string\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import asyncio, aiohttp, httpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def companies(self):\n",
    "    \n",
    "    exchanges = [\"NYSE\", \"NASDAQ\", \"AMEX\", \"OTCBB\"]\n",
    "\n",
    "    def get_companies(exchange=\"NYSE\"):\n",
    "        \"\"\"\n",
    "        :param exchange: The Stock exchange for which you want\n",
    "        to get a current list of all the symbols for.\n",
    "        Default -> NYSE\n",
    "\n",
    "        :returns: a list of tuples containing every company name and symbol in\n",
    "        the market exchange passed to the function\n",
    "        \"\"\"\n",
    "        alpha = list(string.ascii_uppercase)\n",
    "\n",
    "        symbols = []\n",
    "        name = []\n",
    "\n",
    "        # loop through the letters in the alphabet to get the stocks on each page\n",
    "        # from the table and store them in a list\n",
    "        for each in alpha:\n",
    "            url = \"http://eoddata.com/stocklist/{}/{}.htm\".format(\n",
    "                exchange, each)\n",
    "            resp = requests.get(url)\n",
    "            site = resp.content\n",
    "            soup = bs(site, 'html.parser')\n",
    "            table = soup.find('table', {'class': 'quotes'})\n",
    "            for row in table.findAll('tr')[1:]:\n",
    "                symbols.append(row.findAll('td')[0].text.rstrip())\n",
    "            for row in table.findAll('tr')[1:]:\n",
    "                name.append(row.findAll('td')[1].text.rstrip())\n",
    "\n",
    "        # remove the extra letters on the end of the symbols\n",
    "        symbols_clean = []\n",
    "        name_clean = []\n",
    "\n",
    "        for each in symbols:\n",
    "            each = each.replace('.', '-')\n",
    "            symbols_clean.append((each.split('-')[0]))\n",
    "\n",
    "        for each in name:\n",
    "            each = each.replace('.', '-')\n",
    "            name_clean.append((each.split('-')[0]))\n",
    "\n",
    "        return name_clean, symbols_clean\n",
    "\n",
    "    NYSE_company, NYSE_symbol = get_companies(exchanges[0])\n",
    "    NASDAQ_company, NASDAQ_symbol = get_companies(exchanges[1])\n",
    "    AMEX_company, AMEX_symbol = get_companies(exchanges[2])\n",
    "    OTCBB_company, OTCBB_symbol = get_companies(exchanges[3])\n",
    "\n",
    "    columns = [\"exchange\", \"symbol\", \"name\"]\n",
    "\n",
    "    # New York Stock Exchange companies\n",
    "    NYSE = list(zip(NYSE_symbol, NYSE_company))\n",
    "    NYSE = [(\"NYSE\",) + elem for elem in NYSE]\n",
    "    NYSE_df = pd.DataFrame([x for x in NYSE], columns=columns)\n",
    "\n",
    "    # NASDAQ Companies\n",
    "    NASDAQ = list(zip(NASDAQ_symbol, NASDAQ_company))\n",
    "    NASDAQ = [(\"NASDAQ\",) + elem for elem in NASDAQ]\n",
    "    NASDAQ_df = pd.DataFrame([x for x in NASDAQ], columns=columns)\n",
    "\n",
    "    # American Stock Exchange Companies\n",
    "    AMEX = list(zip(AMEX_symbol, AMEX_company))\n",
    "    AMEX = [(\"AMEX\",) + elem for elem in AMEX]\n",
    "    AMEX_df = pd.DataFrame([x for x in AMEX], columns=columns)\n",
    "\n",
    "    # Over the Counter Bulletin Board Exchange \"Pink Sheets\"\n",
    "    # These are the penny stocks and I think their is a lot of\n",
    "    # possibilities with finding a niche in here\n",
    "    OTCBB = list(zip(OTCBB_symbol, OTCBB_company))\n",
    "    OTCBB = [(\"OTCBB\",) + elem for elem in OTCBB]\n",
    "    OTCBB_df = pd.DataFrame([x for x in OTCBB], columns=columns)\n",
    "\n",
    "    # Now we append all the dataframes together so that we have\n",
    "    # one massive master list. Also, the good think is we can still\n",
    "    # use the smaller datasets if need be.\n",
    "\n",
    "    companies_df = NYSE_df.append(NASDAQ_df)\n",
    "    companies_df = companies_df.append(AMEX_df)\n",
    "    companies_df = companies_df.append(OTCBB_df)\n",
    "\n",
    "    # Now check for duplicates and drop them from the main dataset\n",
    "    companies_df = companies_df.drop_duplicates(\n",
    "        subset=\"symbol\", keep=\"first\")\n",
    "    companies_df = companies_df.drop_duplicates(\n",
    "        subset=\"name\", keep=\"first\")\n",
    "\n",
    "    return companies_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "# =========================================================================== #\n",
    "# Fix this function to be neater and handle the cleaning processes:\n",
    "# =========================================================================== #\n",
    "async def async_companie_info(session, each, exchange):\n",
    "    url = \"http://eoddata.com/stocklist/{}/{}.htm\".format(exchange, each)\n",
    "    response = await requests.get(url)\n",
    "    site = response.content\n",
    "    soup = bs(site, 'html.parser')\n",
    "    table = soup.find('table', {'class': 'quotes'})\n",
    "    symbols = [row.findAll('td')[0].text.rstrip() for row in table.findAll('tr')[1:]]\n",
    "    name = [row.findAll('td')[1].text.rstrip() for row in table.findAll('tr')[1:]]\n",
    "\n",
    "    return name, symbols\n",
    "\n",
    "\n",
    "async def get_companies(exchange=\"NYSE\"):\n",
    "    \"\"\"\n",
    "    :param exchange: The Stock exchange for which you want\n",
    "    to get a current list of all the symbols for.\n",
    "    Default -> NYSE\n",
    "\n",
    "    :returns: a list of tuples containing every company name and symbol in\n",
    "    the market exchange passed to the function\n",
    "    \"\"\"\n",
    "    _start = time()\n",
    "    alpha = list(string.ascii_uppercase)\n",
    "\n",
    "    # symbols = []\n",
    "    # name = []\n",
    "\n",
    "    # loop through the letters in the alphabet to get the stocks on each page\n",
    "    # from the table and store them in a list\n",
    "    async with httpx.AsyncClient() as session:\n",
    "        tasks = []\n",
    "        for each in alpha:\n",
    "            tasks.append(async_companie_info(session, each, exchange))\n",
    "            \n",
    "        # Wait for tasks to finish:\n",
    "        await asyncio.gather(*tasks)\n",
    "        \n",
    "    print(\"Asynchronous execution finished in: \", time()-_start)\n",
    "        # for row in table.findAll('tr')[1:]:\n",
    "        #     symbols.append(row.findAll('td')[0].text.rstrip())\n",
    "        # for row in table.findAll('tr')[1:]:\n",
    "        #     name.append(row.findAll('td')[1].text.rstrip())\n",
    "\n",
    "    # # remove the extra letters on the end of the symbols\n",
    "    # symbols_clean = []\n",
    "    # name_clean = []\n",
    "\n",
    "    # for each in symbols:\n",
    "    #     each = each.replace('.', '-')\n",
    "    #     symbols_clean.append((each.split('-')[0]))\n",
    "\n",
    "    # for each in name:\n",
    "    #     each = each.replace('.', '-')\n",
    "    #     name_clean.append((each.split('-')[0]))\n",
    "\n",
    "    # return name_clean, symbols_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e5e182ebf493da2dc5a0b86124f109738a64f3a166517d48ecbde1ce2a4a150"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
